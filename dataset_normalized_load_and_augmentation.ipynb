{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Picture_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        self.files = sorted(files)\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # Нормализации входа & тензоры\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x / 255, dtype='float32')\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('/train')\n",
    "TEST_DIR = Path('/test')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.20, stratify=train_val_labels, random_state=111)\n",
    "\n",
    "val_dataset = Picture_Dataset(val_files, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data_dict = dict(Counter([x.parent.name for x in train_val_files]))\n",
    "data = pd.DataFrame(data = data_dict.values(), index=data_dict.keys(), columns=['count'])\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x = data.index, y = data['count']).set_xticklabels(data.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenters = {\n",
    "    'Crop_comb': transforms.Compose([\n",
    "                                transforms.Resize(size=300, max_size=301),\n",
    "                                transforms.CenterCrop(size=300),\n",
    "                                transforms.RandomCrop(250)\n",
    "                                ]),\n",
    "    'Perspective': transforms.Compose([\n",
    "        transforms.RandomPerspective(distortion_scale=0.3, p=1.0),\n",
    "        transforms.Resize(size=300, max_size=301),\n",
    "        transforms.CenterCrop(size=300),\n",
    "        transforms.RandomCrop(250)\n",
    "        ]),\n",
    "                                       \n",
    "    'Rotate': transforms.RandomRotation(degrees=(-25, 25)),\n",
    "    'HFlip': transforms.RandomHorizontalFlip(p=1),\n",
    "    'Comb1': transforms.Compose([transforms.RandomPerspective(distortion_scale=0.3, p=1.2),\n",
    "                                  transforms.RandomHorizontalFlip(p=1),\n",
    "                                 ]),\n",
    "    'Comb2': transforms.Compose([transforms.RandomPerspective(distortion_scale=0.3, p=1.1),\n",
    "                                 transforms.RandomHorizontalFlip(p=1),\n",
    "                                 transforms.RandomRotation(degrees=(-25, 25)),\n",
    "                                 transforms.Resize(size=300, max_size=301),\n",
    "                                 transforms.CenterCrop(size=300),\n",
    "                                 transforms.RandomCrop(250)\n",
    "                                 ]),\n",
    "    'Comb3': transforms.Compose([transforms.RandomPerspective(distortion_scale=0.2, p=1.2),\n",
    "                                 transforms.RandomHorizontalFlip(p=1),\n",
    "                                 transforms.RandomRotation(degrees=(-15, 15)),\n",
    "                                 transforms.Resize(size=300, max_size=301),\n",
    "                                 transforms.CenterCrop(size=300),\n",
    "                                 transforms.RandomCrop(250),\n",
    "                                 ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Picture_Dataset(train_val_files, mode='train')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=(len(augmenters) + 1),figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    random_character = int(np.random.uniform(0, len(train_val_files)))\n",
    "    img_orig = train_dataset.load_sample(train_val_files[random_character])\n",
    "    img_label = train_val_files[random_character].parent.name\n",
    "    \n",
    "    ax[i][0].imshow(img_orig)\n",
    "    ax[i][0].set_title(img_label)\n",
    "    ax[i][0].axis('off')\n",
    "        \n",
    "    for j, (augmenter_name, augmenter) in enumerate(augmenters.items()):\n",
    "        img_aug = augmenter(img_orig)\n",
    "        ax[i][j + 1].imshow(img_aug)\n",
    "        ax[i][j + 1].set_title(augmenter_name)\n",
    "        ax[i][j + 1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change is_enght filter to valid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_enght = data['count'] < 1500\n",
    "data.loc[is_enght, 'add'] = (1500 - data['count']).astype(int)\n",
    "data.loc[~is_enght, 'add'] = 0\n",
    "data['from_one_image'] = (np.ceil(data['add'] / data['count'])).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "create_dir = Path('/sample')\n",
    "\n",
    "if not os.path.isdir(create_dir):\n",
    "    os.mkdir(create_dir)\n",
    "\n",
    "proc_dataset = Picture_Dataset(train_files, mode='train')\n",
    "\n",
    "for image_path in tqdm(train_files):\n",
    "    path = image_path.parents[0]\n",
    "    character = image_path.parent.name\n",
    "    img = proc_dataset.load_sample(image_path)\n",
    "    \n",
    "    if data.loc[character]['add'] <= 0:\n",
    "        continue\n",
    "  \n",
    "    if data.loc[character]['from_one_image'] > data.loc[character]['add']:\n",
    "        iter_size = data.loc[character]['add']\n",
    "    else:\n",
    "        iter_size = data.loc[character]['from_one_image']\n",
    "    data.loc[character]['add'] -= iter_size\n",
    "    \n",
    "    for i in range(int(iter_size)):\n",
    "        \n",
    "        parent_dir = Path('/sample')\n",
    "        \n",
    "        directory = character\n",
    "        \n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        \n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        augmenter = random.choice(list(augmenters.values()))\n",
    "        aug_img = augmenter(img)\n",
    "        aug_img.save(f\"{path}/{image_path.name.split('.')[0]}_{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DIR = Path('/sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_files = sorted(list(SAMPLE_DIR.rglob('*.jpg')))\n",
    "\n",
    "sample_labels = [path.parent.name for path in train_val_files]\n",
    "\n",
    "train_files.extend(train_sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict(Counter([x.parent.name for x in train_files]))\n",
    "data = pd.DataFrame(data = data_dict.values(), index=data_dict.keys(), columns=['count'])\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x = data.index, y = data['count']).set_xticklabels(data.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Picture_Dataset(train_files, mode='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
