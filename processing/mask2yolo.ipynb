{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathbook.pathbook import *\n",
    "labels = ['klikun', 'maliy', 'shipun']\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotating initial dataset for detection and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing datasets\n",
    "\n",
    "!rm -f ../data/train/*\n",
    "!rm -f ../data/val/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare directories for classification\n",
    "\n",
    "!mkdir ../data/train/klikun\n",
    "!mkdir ../data/train/maliy\n",
    "!mkdir ../data/train/shipun\n",
    "\n",
    "!mkdir ../data/val/klikun\n",
    "!mkdir ../data/val/maliy\n",
    "!mkdir ../data/val/shipun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = 'seg'\n",
    "mode = 'cls'\n",
    "# mode = 'det'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2711/2711 [00:17<00:00, 152.22it/s]\n",
      "100%|██████████| 15357/15357 [01:44<00:00, 147.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in [path_val_dataset, path_train_dataset]:\n",
    "    for img in tqdm(os.listdir(_)):\n",
    "        if img[-4:]=='.jpg':\n",
    "            label = img.split('-')[1]\n",
    "            cv2.imwrite(os.path.join(_,label,img), cv2.imread(os.path.join(_,img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2152/3025 [00:51<00:16, 52.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samedi/Desktop/Минприроды/klikun/images/original (60).jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [01:11<00:00, 42.41it/s]\n",
      "100%|██████████| 3002/3002 [00:46<00:00, 63.93it/s]\n",
      "100%|██████████| 3011/3011 [01:44<00:00, 28.84it/s]\n"
     ]
    }
   ],
   "source": [
    "columns=['set','path','label','x_min','y_min','x_max','y_max']\n",
    "train_array = []\n",
    "val_array = []\n",
    "\n",
    "np.random.seed(17)\n",
    "val_p = 0.15 \n",
    "\n",
    "# iterate through the initial formated for classification dataset\n",
    "dataset = path_initial_train_dataset\n",
    "for label_idx, label in enumerate(labels):\n",
    "    mask_dir = os.path.join(dataset, label, 'masks')\n",
    "    image_dir = os.path.join(dataset, label, 'images')\n",
    "\n",
    "    for file_idx, mask in enumerate(tqdm(os.listdir(mask_dir))):\n",
    "        impath = os.path.join(image_dir, mask.replace('.png','.jpg'))\n",
    "        if not os.path.exists(impath):\n",
    "            # print(impath)\n",
    "            continue # drop masks without images\n",
    "\n",
    "        image = cv2.imread(impath)\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask))\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        h_, w_, _ = mask.shape\n",
    "        if not (h == h_ and w == w_):\n",
    "            continue # drop images with uncorrest masks\n",
    "\n",
    "        save_dir=''\n",
    "        val = (np.random.random() < val_p)\n",
    "        if val:\n",
    "            save_dir = path_val_dataset\n",
    "        else:\n",
    "            save_dir = path_train_dataset\n",
    "\n",
    "        # name format: \"[scource: initial|extra|augmented]-[label: klikun|maliy|shipun]-[ingroup index]]\"\n",
    "        name = f'initial-{label}-{file_idx}'\n",
    "        path = os.path.join(save_dir, name)\n",
    "        if mode == 'cls': # putting images in proper directories for classification task\n",
    "            path = os.path.join(save_dir, label, name)\n",
    "\n",
    "        if not os.path.exists(path+',jpg'): # prevent resouceful rewritting images\n",
    "            cv2.imwrite(path+'.jpg', image)\n",
    "\n",
    "        if mode == 'cls': \n",
    "            continue # no special files are required for classification\n",
    "\n",
    "        with open(path+'.txt','w') as labelfile:\n",
    "\n",
    "            imgray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            colors = np.unique(imgray)[1:]\n",
    "            for color in colors:\n",
    "                #choose one color (one object) from mask and find contours\n",
    "                _, thresh = cv2.threshold(imgray, color, color, type=cv2.THRESH_TOZERO_INV)\n",
    "                _, thresh = cv2.threshold(thresh, color-1, color, type=cv2.THRESH_TOZERO)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                superseg = []\n",
    "                for contour in contours:\n",
    "                    seg = (contour[:,0]/[w,h]).flatten().tolist()\n",
    "                    superseg += seg\n",
    "                    if mode=='seg':\n",
    "                        print(0,*seg,file=labelfile) # save each spot for segmentation rask\n",
    "\n",
    "                # ciunters coords\n",
    "                x = superseg[0::2]\n",
    "                y = superseg[1::2]\n",
    "\n",
    "                if mode=='det':\n",
    "                    print(label_idx,min(x),min(y),max(x),max(y)) # save bboxes for detection\n",
    "\n",
    "                if val:\n",
    "                    val_array.append(['val',path+'.jpg',label,min(x),min(y),max(x),max(y)])\n",
    "                else:\n",
    "                    train_array.append(['train',path+'.jpg',label,min(x),min(y),max(x),max(y)])\n",
    "\n",
    "if mode!='cls': #save annotations for detection\n",
    "    pd.DataFrame(train_array, columns=columns).to_csv(path_train_annotation,index=False)\n",
    "    pd.DataFrame(val_array, columns=columns).to_csv(path_val_annotation,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
