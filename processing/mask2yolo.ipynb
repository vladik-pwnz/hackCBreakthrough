{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathbook.pathbook import *\n",
    "labels = ['klikun', 'maliy', 'shipun']\n",
    "labeldict = {'klikun':0, 'maliy':1, 'shipun':2}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_test_annotation)\n",
    "for img in df['path'].unique():\n",
    "    with open(path_test_dataset / img.replace('.jpg','.txt'),'w') as txt:\n",
    "        info = df[df['path']==img].copy()\n",
    "        info['x']=(info.x_min+info.x_max)/2\n",
    "        info['y']=(info.y_min+info.y_max)/2\n",
    "        info['w']=(-info.x_min+info.x_max)\n",
    "        info['h']=(-info.y_min+info.y_max)\n",
    "        for idx, row in info.iterrows():\n",
    "            print(labeldict[row.label],row.x,row.y,row.w,row.h,file=txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:00<00:00, 2730.50it/s]\n",
      "100%|██████████| 904/904 [00:00<00:00, 2776.12it/s]\n",
      "100%|██████████| 904/904 [00:00<00:00, 3028.61it/s]\n",
      "100%|██████████| 5122/5122 [00:01<00:00, 3543.36it/s]\n",
      "100%|██████████| 5132/5132 [00:01<00:00, 3864.61it/s]\n",
      "100%|██████████| 5100/5100 [00:01<00:00, 4074.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in [path_val_dataset, path_train_dataset]:\n",
    "    for dir in os.listdir(s):\n",
    "        for path in tqdm(os.listdir(os.path.join(s,dir))):\n",
    "            if path[-4:]=='.txt':\n",
    "                path = os.path.join(s,dir,path)\n",
    "                with open(path,'r') as file:\n",
    "                    lines = file.readlines()\n",
    "                with open(path,'w') as file:\n",
    "                    for line in lines:\n",
    "                        print(str(labeldict[path.split('/')[-1].split('-')[1]]),line[2:],file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2711/2711 [00:17<00:00, 152.22it/s]\n",
      "100%|██████████| 15357/15357 [01:44<00:00, 147.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in [path_val_dataset, path_train_dataset]:\n",
    "    for img in tqdm(os.listdir(_)):\n",
    "        if img[-4:]=='.jpg':\n",
    "            label = img.split('-')[1]\n",
    "            cv2.imwrite(os.path.join(_,label,img), cv2.imread(os.path.join(_,img)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segmentations from initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [01:22<00:00, 36.70it/s]\n",
      "100%|██████████| 3002/3002 [00:54<00:00, 54.61it/s]\n",
      "100%|██████████| 3011/3011 [01:57<00:00, 25.70it/s]\n"
     ]
    }
   ],
   "source": [
    "columns=['set','path','class_name','class_id','x_min','y_min','x_max','y_max']\n",
    "train_array = []\n",
    "val_array = []\n",
    "\n",
    "np.random.seed(17)\n",
    "val_p = 0.15 \n",
    "\n",
    "# iterate through the initial formated for classification dataset\n",
    "dataset = path_initial_train_dataset\n",
    "for label_idx, label in enumerate(labels):\n",
    "    mask_dir = os.path.join(dataset, label, 'masks')\n",
    "    image_dir = os.path.join(dataset, label, 'images')\n",
    "\n",
    "    for file_idx, mask in enumerate(tqdm(os.listdir(mask_dir))):\n",
    "        impath = os.path.join(image_dir, mask.replace('.png','.jpg'))\n",
    "        if not os.path.exists(impath):\n",
    "            # print(impath)\n",
    "            continue # drop masks without images\n",
    "\n",
    "        image = cv2.imread(impath)\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask))\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        h_, w_, _ = mask.shape\n",
    "        if not (h == h_ and w == w_):\n",
    "            continue # drop images with uncorrest masks\n",
    "\n",
    "        save_dir=''\n",
    "        save_cls_dir=''\n",
    "        val = (np.random.random() < val_p)\n",
    "        if val:\n",
    "            save_dir = path_val_dataset\n",
    "            save_cls_dir = path_cls_val_dataset\n",
    "        else:\n",
    "            save_dir = path_train_dataset\n",
    "            save_cls_dir = path_cls_train_dataset\n",
    "\n",
    "        # name format: \"[scource: initial|extra|augmented]-[label: klikun|maliy|shipun]-[ingroup index]]\"\n",
    "        name = f'initial-{label}-{file_idx}'\n",
    "        path = os.path.join(save_dir, label, name)\n",
    "\n",
    "        # saving image and annotation for segmentation task\n",
    "        cv2.imwrite(path+'.jpg', image)\n",
    "        with open(path+'.txt','w') as labelfile:\n",
    "\n",
    "            imgray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            colors = np.unique(imgray)[1:]\n",
    "            for color_idx, color in enumerate(colors):\n",
    "                #choose one color (one object) from mask and find contours\n",
    "                _, thresh = cv2.threshold(imgray, color, color, type=cv2.THRESH_TOZERO_INV)\n",
    "                _, thresh = cv2.threshold(thresh, color-1, color, type=cv2.THRESH_TOZERO)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                superseg = []\n",
    "                for contour in contours:\n",
    "                    seg = (contour[:,0]/[w,h]).flatten().tolist()\n",
    "                    superseg += seg\n",
    "                    # if mode=='seg':\n",
    "                    print(0,*seg,file=labelfile) # save each spot for segmentation task\n",
    "\n",
    "                # contours coords\n",
    "                x = superseg[0::2]\n",
    "                x_min = min(x)\n",
    "                x_max = max(x)\n",
    "\n",
    "                y = superseg[1::2]\n",
    "                y_min = min(y)\n",
    "                y_max = max(y)\n",
    "\n",
    "                w_ = x_max-x_min\n",
    "                h_ = y_max-y_min\n",
    "\n",
    "                # saving different crops for classification task\n",
    "                cls_path = os.path.join(save_cls_dir, label, name+f\"-{color_idx}\")\n",
    "                cls_a_path = os.path.join(save_cls_dir, label, f'augmented-{label}-{file_idx}-{color_idx}')\n",
    "                cv2.imwrite(cls_a_path+'-1'+'.jpg', \n",
    "                            image[int(y_min*h) : int(y_max*h), \n",
    "                                  int(x_min*w) : int(x_max*w)])\n",
    "                if w_ < 0.8 and h_ < 0.8:\n",
    "                    cv2.imwrite(cls_path+'-1.2'+'.jpg', \n",
    "                            image[int(max((y_min-0.1*h_),0)*h) : int(min((y_max+0.1*h_),1)*h), \n",
    "                                  int(max((x_min-0.1*w_),0)*w) : int(min((x_max+0.1*w_),1)*w)])\n",
    "                if w_ < 0.6 and h_ < 0.6:\n",
    "                    cv2.imwrite(cls_a_path+'-1.4'+'.jpg', \n",
    "                            image[int(max((y_min-0.2*h_),0)*h) : int(min((y_max+0.2*h_),1)*h), \n",
    "                                  int(max((x_min-0.2*w_),0)*w) : int(min((x_max+0.2*w_),1)*w)])\n",
    "\n",
    "                # if mode=='det':\n",
    "                #     print(label_idx,min(x),min(y),max(x),max(y)) # save bboxes for detection\n",
    "\n",
    "                if val:\n",
    "                    val_array.append(['val',path+'.jpg',label,labeldict[label],x_min,y_min,x_max,y_max])\n",
    "                else:\n",
    "                    train_array.append(['train',path+'.jpg',label,labeldict[label],x_min,y_min,x_max,y_max])\n",
    "\n",
    "# if mode!='cls': #save annotations for detection\n",
    "pd.DataFrame(train_array, columns=columns).to_csv(path_train_annotation,index=False)\n",
    "pd.DataFrame(val_array, columns=columns).to_csv(path_val_annotation,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_test_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set           251.jpg\n",
       "x_min         251.jpg\n",
       "y_min         251.jpg\n",
       "x_max         251.jpg\n",
       "y_max         251.jpg\n",
       "class_name    251.jpg\n",
       "class_id      251.jpg\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('path').count().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in df['path'].unique()[:]:\n",
    "    path = os.path.join(path_test_dataset,img.replace('.jpg','.txt'))\n",
    "    lines=[]\n",
    "    with open(path,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(path,'w') as f:\n",
    "        for line, id in zip(lines,df[df['path']==img]['class_id']):\n",
    "            print(str(id) + line[1:-1],file=f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cls dataset\n",
    "crops of initial images with 20% padings:\n",
    "cls_image_size / bbox_size = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../dataset/classification\n",
    "!mkdir ../dataset/classification\n",
    "!mkdir ../dataset/classification/test\n",
    "!mkdir ../dataset/classification/test/klikun\n",
    "!mkdir ../dataset/classification/test/maliy\n",
    "!mkdir ../dataset/classification/test/shipun\n",
    "!mkdir ../dataset/classification/val\n",
    "!mkdir ../dataset/classification/val/klikun\n",
    "!mkdir ../dataset/classification/val/maliy\n",
    "!mkdir ../dataset/classification/val/shipun\n",
    "!mkdir ../dataset/classification/train\n",
    "!mkdir ../dataset/classification/train/klikun\n",
    "!mkdir ../dataset/classification/train/maliy\n",
    "!mkdir ../dataset/classification/train/shipun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [01:47<00:00, 28.21it/s]\n",
      "100%|██████████| 3002/3002 [01:06<00:00, 44.81it/s]\n",
      "100%|██████████| 3011/3011 [02:35<00:00, 19.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(path_train_annotation)\n",
    "df_val=pd.read_csv(path_val_annotation)\n",
    "df_test=pd.read_csv(path_test_annotation)\n",
    "\n",
    "dataset = path_initial_train_dataset\n",
    "for label_idx, label in enumerate(labels):\n",
    "    mask_dir = os.path.join(dataset, label, 'masks')\n",
    "    image_dir = os.path.join(dataset, label, 'images')\n",
    "\n",
    "    for file_idx, mask in enumerate(tqdm(os.listdir(mask_dir))):\n",
    "        impath = os.path.join(image_dir, mask.replace('.png','.jpg'))\n",
    "        if not os.path.exists(impath):\n",
    "            # print(impath)\n",
    "            continue # drop masks without images\n",
    "\n",
    "        image = cv2.imread(impath)\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask))\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        h_, w_, _ = mask.shape\n",
    "        if not (h == h_ and w == w_):\n",
    "            continue # drop images with uncorrect masks\n",
    "\n",
    "        # name format: \"[scource: initial|extra|augmented]-[label: klikun|maliy|shipun]-[ingroup index]]\"\n",
    "        name = f'initial-{label}-{file_idx}'\n",
    "\n",
    "        save_cls_dir=''\n",
    "        if label+'/'+name+'.jpg' in df_train['path'].values:\n",
    "            save_cls_dir = path_cls_train_dataset \n",
    "        elif label+'/'+name+'.jpg' in df_val['path'].values:\n",
    "            save_cls_dir = path_cls_val_dataset\n",
    "        elif label+'/'+name+'.jpg' in df_test['path'].values:\n",
    "            save_cls_dir = path_cls_test_dataset\n",
    "        else:\n",
    "            # print(impath, name)\n",
    "            continue\n",
    "\n",
    "        imgray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        for color_idx, color in enumerate(np.unique(imgray)[1:]):\n",
    "            _, thresh = cv2.threshold(imgray, color, color, type=cv2.THRESH_TOZERO_INV)\n",
    "            _, thresh = cv2.threshold(thresh, color-1, color, type=cv2.THRESH_TOZERO)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # returns only most parental (external) contours\n",
    "            \n",
    "            superseg = []\n",
    "            for contour in contours:\n",
    "                seg = (contour[:,0]/[w,h]).flatten().tolist()\n",
    "                superseg += seg\n",
    "\n",
    "            # contours coords\n",
    "            x = superseg[0::2]\n",
    "            x_min = min(x)\n",
    "            x_max = max(x)\n",
    "            x_c = (x_min + x_max)/2*w\n",
    "\n",
    "            y = superseg[1::2]\n",
    "            y_min = min(y)\n",
    "            y_max = max(y)\n",
    "            y_c = (y_max+y_min)/2*h\n",
    "\n",
    "            size = max((y_max-y_min)*h, (x_max-x_min)*w)\n",
    "\n",
    "            X_min = int(x_c - 1.4*size/2)\n",
    "            X_max = int(x_c + 1.4*size/2)\n",
    "            Y_min = int(y_c - 1.4*size/2)\n",
    "            Y_max = int(y_c + 1.4*size/2)\n",
    "\n",
    "            if X_min < 0: \n",
    "                X_max = min(X_max - X_min, w)\n",
    "                X_min = 0\n",
    "            if X_max > w:\n",
    "                X_min = max(X_min - X_max + w, 0)\n",
    "                X_max = w\n",
    "            if Y_min < 0:\n",
    "                Y_max = min(Y_max - Y_min, h)\n",
    "                Y_min = 0\n",
    "            if Y_max > h:\n",
    "                Y_min = max(Y_min - Y_max + h, 0)\n",
    "                Y_max = h\n",
    "\n",
    "\n",
    "            cv2.imwrite(os.path.join(save_cls_dir, label, name+f\"-{color_idx}.jpg\"), \n",
    "                        image[Y_min : Y_max, X_min : X_max])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empty masks:\n",
    "\n",
    "/Users/samedi/Desktop/swans/maliy/images/2841811261.jpg     initial-maliy-301\n",
    "\n",
    "/Users/samedi/Desktop/swans/maliy/images/3802649513.jpg     initial-maliy-646\n",
    "\n",
    "/Users/samedi/Desktop/swans/shipun/images/img_2646.jpg      initial-shipun-2028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_train_annotation)\n",
    "test=[]\n",
    "train=[]\n",
    "for label in labels:\n",
    "    df = df_train[df_train['class_name']==label].copy().reset_index()\n",
    "    flag = df[df['path']==df['path'].unique()[100]].index[-1] + 1\n",
    "    test.append(df.iloc[:flag])\n",
    "    train.append(df.iloc[flag:])\n",
    "df_train = pd.concat(train)\n",
    "df_test = pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=['index']).to_csv(path_test_annotation, index=False)\n",
    "df_train.drop(columns=['index']).to_csv(path_train_annotation, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train->test\n",
    "df_test = pd.read_csv(path_test_annotation)\n",
    "for path in df_test['path'].unique():\n",
    "    shutil.move(os.path.join(path_train_dataset,path.replace('.jpg','.txt')),\n",
    "                os.path.join(path_test_dataset,path.replace('.jpg','.txt')))\n",
    "    # for i, croppath in enumerate(df_test[df_test['path']==path]['path']):\n",
    "    #     croppath = croppath.replace('.jpg', '-' + str(i) + '.jpg')\n",
    "    #     shutil.move(os.path.join(path_cls_train_dataset,croppath),\n",
    "    #                 os.path.join(path_cls_test_dataset,croppath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test->train\n",
    "# for path in df_test['path'].unique():\n",
    "#     shutil.move(\n",
    "#                 os.path.join(path_test_dataset,path),os.path.join(path_train_dataset,path))\n",
    "#     for i, croppath in enumerate(df_test[df_test['path']==path]['path']):\n",
    "#         croppath = croppath.replace('.jpg', '-' + str(i) + '.jpg')\n",
    "#         shutil.move(\n",
    "#                     os.path.join(path_cls_test_dataset,croppath),os.path.join(path_cls_train_dataset,croppath))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remake segmentation annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7371/7371 [00:04<00:00, 1567.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>an</th>\n",
       "      <th>sn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klikun/initial-klikun-122.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klikun/initial-klikun-123.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>klikun/initial-klikun-125.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klikun/initial-klikun-126.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>klikun/initial-klikun-127.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            path  an  sn\n",
       "0  klikun/initial-klikun-122.jpg   2   3\n",
       "1  klikun/initial-klikun-123.jpg   1   1\n",
       "2  klikun/initial-klikun-125.jpg   1   1\n",
       "3  klikun/initial-klikun-126.jpg   1   1\n",
       "4  klikun/initial-klikun-127.jpg   1   1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.read_csv(path_train_annotation)\n",
    "number = {'path':[],'an':[],'sn':[]}\n",
    "for path in tqdm(df_train['path'].unique()):\n",
    "    with open(os.path.join(path_train_dataset, path.replace('.jpg','.txt'))) as f:\n",
    "        an = df_train[df_train['path']==path]['path'].size\n",
    "        lines = f.readlines()\n",
    "        sn = 0\n",
    "        for line in lines:\n",
    "            sn += line!='\\n'\n",
    "        number['path'].append(path)\n",
    "        number['an'].append(an)\n",
    "        number['sn'].append(sn)\n",
    "number = pd.DataFrame(number)\n",
    "number.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(number['an']<number['sn']).sum() # after remaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [01:34<00:00, 32.07it/s]\n",
      "100%|██████████| 3002/3002 [01:09<00:00, 43.45it/s]\n",
      "100%|██████████| 3011/3011 [01:56<00:00, 25.78it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(path_train_annotation)\n",
    "df_val=pd.read_csv(path_val_annotation)\n",
    "df_test=pd.read_csv(path_test_annotation)\n",
    "\n",
    "dataset = path_initial_train_dataset\n",
    "for label_idx, label in enumerate(labels):\n",
    "    mask_dir = os.path.join(dataset, label, 'masks')\n",
    "    image_dir = os.path.join(dataset, label, 'images')\n",
    "\n",
    "    for file_idx, mask in enumerate(tqdm(os.listdir(mask_dir))):\n",
    "        impath = os.path.join(image_dir, mask.replace('.png','.jpg'))\n",
    "        if not os.path.exists(impath):\n",
    "            # print(impath)\n",
    "            continue # drop masks without images\n",
    "\n",
    "        image = cv2.imread(impath)\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask))\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        h_, w_, _ = mask.shape\n",
    "        if not (h == h_ and w == w_):\n",
    "            continue # drop images with uncorrect masks\n",
    "\n",
    "        # name format: \"[scource: initial|extra|augmented]-[label: klikun|maliy|shipun]-[ingroup index]]\"\n",
    "        name = f'initial-{label}-{file_idx}'\n",
    "\n",
    "        save_dir=''\n",
    "        if label+'/'+name+'.jpg' in df_train['path'].values:\n",
    "            save_dir = path_train_dataset \n",
    "        elif label+'/'+name+'.jpg' in df_val['path'].values:\n",
    "            save_dir = path_val_dataset\n",
    "        elif label+'/'+name+'.jpg' in df_test['path'].values:\n",
    "            save_dir = path_test_dataset\n",
    "        else:\n",
    "            # print(impath, name)\n",
    "            continue\n",
    "\n",
    "\n",
    "        path = os.path.join(save_dir, label, name)\n",
    "        with open(path+'.txt','w') as labelfile:\n",
    "\n",
    "            imgray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            for color_idx, color in enumerate(np.unique(imgray)[1:]):\n",
    "                _, thresh = cv2.threshold(imgray, color, color, type=cv2.THRESH_TOZERO_INV)\n",
    "                _, thresh = cv2.threshold(thresh, color-1, color, type=cv2.THRESH_TOZERO)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "                # RETR_EXTERNAL -> returns only most parental (external) contours\n",
    "                \n",
    "                for contour in contours:\n",
    "                    seg = (contour[:,0]/[w,h]).flatten().tolist()\n",
    "                    print(labeldict[label],*seg,file=labelfile) # save each spot for segmentation task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
