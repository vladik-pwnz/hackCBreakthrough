{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.backends.cuda' has no attribute 'is_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39mis_available())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samedi/Documents/Coding/swans/model/yolov8/train.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m device\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.backends.cuda' has no attribute 'is_available'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cpu'\n",
    "print('mps', torch.backends.mps.is_available())\n",
    "if torch.backends.cuda.is_available():\n",
    "    device = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"./runs/segment/train4/weights/last.pt\")  # load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.109 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mimgsize\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['imgsz=640', 'optimize=False', 'visualize=False'].\n\n    Arguments received: ['yolo', '--ip=127.0.0.1', '--stdin=9013', '--control=9011', '--hb=9010', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"d5aad18a-d460-4a97-8599-4dc43a65a16e\"', '--shell=9012', '--transport=\"tcp\"', '--iopub=9014', '--f=/Users/samedi/Library/Jupyter/runtime/kernel-v2-646545Sos9AgFjrJ4.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3398\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [11]\u001b[0m in \u001b[1;35m<cell line: 1>\u001b[0m\n    model.train(data=\"/Users/samedi/Documents/Coding/swans/model/yolov8/config/swans.yaml\", epochs=15, device=\"cpu\", imgsize=224)  # train the model\n",
      "  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:366\u001b[0m in \u001b[1;35mtrain\u001b[0m\n    self.trainer = TASK_MAP[self.task][1](overrides=overrides, _callbacks=self.callbacks)\n",
      "  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/yolo/v8/segment/train.py:25\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\n",
      "  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:82\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\n",
      "  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/yolo/cfg/__init__.py:111\u001b[0m in \u001b[1;35mget_cfg\u001b[0m\n    check_cfg_mismatch(cfg, overrides)\n",
      "\u001b[0;36m  File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/yolo/cfg/__init__.py:181\u001b[0;36m in \u001b[0;35mcheck_cfg_mismatch\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mimgsize\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['imgsz=640', 'optimize=False', 'visualize=False'].\n\n    Arguments received: ['yolo', '--ip=127.0.0.1', '--stdin=9013', '--control=9011', '--hb=9010', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"d5aad18a-d460-4a97-8599-4dc43a65a16e\"', '--shell=9012', '--transport=\"tcp\"', '--iopub=9014', '--f=/Users/samedi/Library/Jupyter/runtime/kernel-v2-646545Sos9AgFjrJ4.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "model.train(data=\"/Users/samedi/Documents/Coding/swans/model/yolov8/config/swans-seg.yaml\", \n",
    "            epochs=15, \n",
    "            device=device, \n",
    "            imgsize=224,)\n",
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/samedi/Documents/Coding/swans/data/train/initial-klikun-1.jpg: 480x640 2 klikuns, 1 shipun, 129.1ms\n",
      "Speed: 26.5ms preprocess, 129.1ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "result=model(\"/Users/samedi/Documents/Coding/swans/data/train/initial-klikun-1.jpg\", \n",
    "             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
